{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Stratified k-fold cross-validation in PySpark\"\n",
    "description: |\n",
    "  Running stratified k-fold cross-validation in pure PySpark by splitting the data into\n",
    "  folds manually and passing them to the `foldCol` argument.\n",
    "author: \"Ivan Dubrovin\"\n",
    "date: \"2023-04-17\"\n",
    "categories: [Python, PySpark]\n",
    "image: cover.png\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have recently been experimenting with implementing automated feature extraction and evaluation techniques in PySpark.\n",
    "Some of them rely on running repeated k-fold cross-validation.\n",
    "PySpark provides the [`CrossValidator`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html) object for precisely that.\n",
    "However, simple random splits are not a suitable approach when the data is heavily imbalanced, which it often is.\n",
    "This short post shows a way to use the [`CrossValidator`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html) for running ***stratified*** k-fold cross-validation that keeps the class distribution similar across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have completed all the preprocessing and stored the results in a Data Frame `proc` that has two columns: `target` and `features`.\n",
    "The `target` in this minimal example is binary, but the same approach applies to a multiclass case.\n",
    "For regression, an additional step of creating quantile buckets can be added to use this approach.\n",
    "The `features` column is the vector of features: output of the [`VectorAssembler`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.VectorAssembler.html) transformer.\n",
    "Its schema would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- target: long (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proc.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in `proc` is imbalanced, so pure k-fold cross-validation is unreliable.\n",
    "However, [`CrossValidator`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html) provides a possibility to specify the folds manually, which allows us to run more fancy versions of cross-validation using the same object.\n",
    "The folds have to be stored in a column whose name is passed to the `foldCol` argument of the [`CrossValidator`](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.tuning.CrossValidator.html) constructor. \n",
    "During $i$th iteration, rows with value $i$ in the `foldCol` are used as the validation set, and the rest are used for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple way to split the data into folds in a stratified fasion is to apply the [`ntile`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ntile.html) window function using partitions of the data by `target` and ordering by a random column to shuffle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "proc = proc.withColumn(\n",
    "    \"fold\",\n",
    "    F.ntile(k).over(Window.partitionBy(\"target\").orderBy(F.rand())) - 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function assigns every row to one of $k$ evenly split groups.\n",
    "Subtracting one converts the tile number to the index of the fold.\n",
    "Here is how the data is split across the folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+\n",
      "|fold|target| count|\n",
      "+----+------+------+\n",
      "|   0|     0|234162|\n",
      "|   1|     0|234161|\n",
      "|   2|     0|234161|\n",
      "|   3|     0|234161|\n",
      "|   4|     0|234161|\n",
      "|   0|     1| 29987|\n",
      "|   1|     1| 29987|\n",
      "|   2|     1| 29987|\n",
      "|   3|     1| 29987|\n",
      "|   4|     1| 29987|\n",
      "+----+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "proc.groupBy(\"fold\", \"target\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All folds have consistent target rates and shoud provide a more stable estimation of the error.\n",
    "Now set up a model and an evaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"target\",\n",
    "    predictionCol=\"prediction\",\n",
    "    probabilityCol=\"probability\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    numTrees=350,\n",
    "    maxDepth=7,\n",
    "    maxBins=128,\n",
    "    minInstancesPerNode=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    labelCol=\"target\",\n",
    "    metricName=\"areaUnderROC\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run the cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(\n",
    "    estimator=rfc,\n",
    "    estimatorParamMaps=ParamGridBuilder().build(),\n",
    "    evaluator=binary_evaluator,\n",
    "    numFolds=k,\n",
    "    foldCol=\"fold\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm = cv.fit(proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the result is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6324294190273916]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvm.avgMetrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 (PYENV.MLPY388)",
   "language": "python",
   "name": "pyenv.mlpy388"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
